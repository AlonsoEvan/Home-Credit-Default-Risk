{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model):\n",
    "    return cross_val_score(model, df_train, labels, scoring='roc_auc', cv = KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(var_name, df):\n",
    "    corr = df['TARGET'].corr(df[var_name])\n",
    "    \n",
    "    median_repaid = df.loc[df['TARGET'] == 0, var_name].median()\n",
    "    median_not_repaid = df.loc[df['TARGET'] == 1, var_name].median()\n",
    "    \n",
    "    plt.figure(figsize = (10,8))\n",
    "    sns.kdeplot(df.loc[df['TARGET'] == 0, var_name], label = 'target = 0')\n",
    "    sns.kdeplot(df.loc[df['TARGET'] == 1, var_name], label = 'target = 1')\n",
    "    plt.xlabel(var_name)\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Density with TARGET')\n",
    "    plt.legend();\n",
    "    \n",
    "    print('The correlation between {} and the TARGET is {}'.format(var_name, corr))\n",
    "    print('')\n",
    "    print('The median value for loan that was repaid is :', median_repaid)\n",
    "    print('')\n",
    "    print('The median value for loan that was not repaid is :', median_not_repaid)\n",
    "    \n",
    "#corr('previous_loan_counts', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categorical(df, group_var, df_name):\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "    categorical[group_var] = df[group_var] \n",
    "    \n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    columns = []\n",
    "\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name for the variable and stat\n",
    "            columns.append('%s_%s' % (var, stat))\n",
    "\n",
    "    categorical.columns = columns\n",
    "    \n",
    "    return categorical\n",
    "\n",
    "#bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var]\n",
    "    numeric_df = df.select_dtypes('number')\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg\n",
    "\n",
    "#bureau_agg_new = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(df, cv):\n",
    "    \n",
    "    y = df['TARGET']\n",
    "    X = df.drop(columns = ['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "    \n",
    "    feature_names = list(X.columns)\n",
    "    \n",
    "    \n",
    "    le = LabelEncoder()\n",
    "\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtypes == 'object':\n",
    "            if len(list(X[col].unique())) <= 2:\n",
    "                X[col] = le.fit_transform(X[col])\n",
    "    \n",
    "    X = pd.get_dummies(X)\n",
    "    \n",
    "    Imputer = SimpleImputer(strategy = 'median')\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    X = Imputer.fit_transform(X)\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    \n",
    "    scores = cross_validate(model, X, y, cv = cv, scoring = 'roc_auc', return_train_score = True)\n",
    "    \n",
    "   \n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_importance(df):\n",
    "\n",
    "    y = df['TARGET']\n",
    "    X = df.drop(columns = ['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    le = LabelEncoder()\n",
    "\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtypes == 'object':\n",
    "            if len(list(X[col].unique())) <= 2:\n",
    "                X[col] = le.fit_transform(X[col])\n",
    "    \n",
    "    X = pd.get_dummies(X)\n",
    "    \n",
    "    feature_names = list(X.columns)\n",
    "    \n",
    "    Imputer = SimpleImputer(strategy = 'median')\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    X = Imputer.fit_transform(X)\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model1 = model.fit(X, y)\n",
    "    \n",
    "    \n",
    "    feat_importances_values = model1.feature_importances_ \n",
    "    \n",
    "    feat_importances = pd.DataFrame({'feature': feature_names, 'importance': feat_importances_values})\n",
    "    \n",
    "    return feat_importances.sort_values(by = 'importance' ,ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(train, test):\n",
    "    \n",
    "    \n",
    "        y = train['TARGET']\n",
    "        X_train = train.drop(columns = ['SK_ID_CURR', 'TARGET'], axis = 1)\n",
    "        X_test = test.drop(columns = ['SK_ID_CURR'], axis = 1)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        le = LabelEncoder()\n",
    "\n",
    "\n",
    "        for col in X_train.columns:\n",
    "            if X_train[col].dtypes == 'object':\n",
    "                if len(list(X_train[col].unique())) <= 2:\n",
    "                    X_train[col] = le.fit_transform(X_train[col])\n",
    "                    X_test[col] = le.transform(X_test[col])\n",
    "                    \n",
    "    \n",
    "        X_train = pd.get_dummies(X_train)\n",
    "        X_test = pd.get_dummies(X_test)\n",
    "        \n",
    "        X_train, X_test = X_train.align(X_test, join = 'inner', axis = 1)\n",
    "    \n",
    "        Imputer = SimpleImputer(strategy = 'median')\n",
    "        \n",
    "        scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "        X_train = Imputer.fit_transform(X_train)\n",
    "        X_test = Imputer.transform(X_test)\n",
    "    \n",
    "\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        LGBM = LGBMClassifier().fit(X_train, y)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        predictions = LGBM.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        LGBM = pd.DataFrame()\n",
    "        LGBM['SK_ID_CURR'] = test_id\n",
    "        LGBM['TARGET'] = predictions\n",
    "        LGBM.to_csv(\"LGBM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(hyperparameters, iteration):\n",
    "    \"\"\"Objective function for grid and random search. Returns\n",
    "       the cross validation score from a set of hyperparameters.\"\"\"\n",
    "    \n",
    "    # Number of estimators will be found using early stopping\n",
    "    if 'n_estimators' in hyperparameters.keys():\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "     # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 42)\n",
    "    \n",
    "    # results to retun\n",
    "    score = cv_results['auc-mean'][-1]\n",
    "    estimators = len(cv_results['auc-mean'])\n",
    "    hyperparameters['n_estimators'] = estimators \n",
    "    \n",
    "    return [score, hyperparameters, iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def grid_search(param_grid, max_evals = MAX_EVALS):\n",
    "    \"\"\"Grid search algorithm (with limit on max evals)\"\"\"\n",
    "    \n",
    "    # Dataframe to store results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                              index = list(range(MAX_EVALS)))\n",
    "    \n",
    "    # https://codereview.stackexchange.com/questions/171173/list-all-possible-permutations-from-a-python-dictionary-of-lists\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    # Iterate through every possible combination of hyperparameters\n",
    "    for v in itertools.product(*values):\n",
    "        \n",
    "        # Create a hyperparameter dictionary\n",
    "        hyperparameters = dict(zip(keys, v))\n",
    "        \n",
    "        # Set the subsample ratio accounting for boosting type\n",
    "        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n",
    "        \n",
    "        # Evalute the hyperparameters\n",
    "        eval_results = objective(hyperparameters, i)\n",
    "        \n",
    "        results.loc[i, :] = eval_results\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        # Normally would not limit iterations\n",
    "        if i > MAX_EVALS:\n",
    "            break\n",
    "       \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "    \n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(50)\n",
    "\n",
    "def random_search(param_grid, max_evals = MAX_EVALS):\n",
    "    \"\"\"Random search for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # Dataframe for results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                                  index = list(range(MAX_EVALS)))\n",
    "    \n",
    "    # Keep searching until reach max evaluations\n",
    "    for i in range(MAX_EVALS):\n",
    "        \n",
    "        # Choose random hyperparameters\n",
    "        hyperparameters = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n",
    "\n",
    "        # Evaluate randomly selected hyperparameters\n",
    "        eval_results = objective(hyperparameters, i)\n",
    "        \n",
    "        results.loc[i, :] = eval_results\n",
    "    \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_features(train, test, degree):\n",
    "    \n",
    "    print('Training shape :', train.shape)\n",
    "    print('Testing shape :', test.shape)\n",
    "\n",
    "    poly_feat = train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
    "\n",
    "\n",
    "    poly_feat_test = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "\n",
    "\n",
    "    imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "    poly_target = poly_feat['TARGET']\n",
    "    poly_feat = poly_feat.drop(columns = ['TARGET'])\n",
    "\n",
    "    poly_feat = imputer.fit_transform(poly_feat)\n",
    "    poly_feat_test = imputer.transform(poly_feat_test)\n",
    "\n",
    "    #polynomial transformations\n",
    "    poly_transformer = PolynomialFeatures(degree = degree)\n",
    "\n",
    "    poly_feat = poly_transformer.fit_transform(poly_feat)\n",
    "    poly_feat_test = poly_transformer.transform(poly_feat_test)\n",
    "\n",
    "    print('\\nPolynomial features shapes :', poly_feat.shape)\n",
    "    print('Polynomial features shapes:' , poly_feat_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "    poly_feat = pd.DataFrame(poly_feat, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                               'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "    poly_feat['TARGET'] = poly_target\n",
    "\n",
    "    poly_corr = poly_feat.corr()['TARGET'].abs().sort_values(ascending = False)\n",
    "    \n",
    "    print('\\nCorrelation between TARGET and polynomial features')\n",
    "    print('')\n",
    "    print(poly_corr)\n",
    "\n",
    "    # Put test features into dataframe\n",
    "    poly_feat_test = pd.DataFrame(poly_feat_test, \n",
    "                                      columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                                    'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "    # Merge polynomial features into training dataframe\n",
    "    poly_feat['SK_ID_CURR'] = train['SK_ID_CURR']\n",
    "    train_poly = train.merge(poly_feat, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "    # Merge polynomial features into testing dataframe\n",
    "    poly_feat_test['SK_ID_CURR'] = test['SK_ID_CURR']\n",
    "    test_poly = test.merge(poly_feat_test, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "    train_poly, test_poly = train_poly.align(test_poly, join = 'inner', axis = 1)\n",
    "\n",
    "    print('\\nTraining polynomial data shapes :', train_poly.shape)\n",
    "    print('Testing polynomial data shapes :', test_poly.shape)\n",
    "    \n",
    "    return train_poly, test_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_sel(train, test):\n",
    "    \n",
    "    tr_labels = train['TARGET']\n",
    "    \n",
    "    train = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test = test.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    print('Phase Label encoder')\n",
    "    #LABEL ENCODER\n",
    "    le = LabelEncoder()\n",
    "\n",
    "\n",
    "    # Iterate through the columns\n",
    "    for col in train:\n",
    "        if train[col].dtype == 'object':\n",
    "            # If 2 or fewer unique categories\n",
    "            if len(list(train[col].unique())) <= 2:\n",
    "                # Train on the training data\n",
    "                le.fit(train[col])\n",
    "                # Transform both training and testing data\n",
    "                train[col] = le.transform(train[col])\n",
    "                test[col] = le.transform(test[col])\n",
    "                \n",
    "    print('\\nDummyfication')\n",
    "    \n",
    "    #GET DUMMY\n",
    "    train = pd.get_dummies(train)\n",
    "    test = pd.get_dummies(test)\n",
    "    \n",
    "    #ALIGN\n",
    "    \n",
    "    train, test = train.align(test, join = 'inner', axis = 1)\n",
    "    \n",
    "    print('\\nNumber of feature in the training data after label encoder and get dummy: ', train.shape[1])\n",
    "    print('Number of feature in the testing data after label encoder and get dummy: ', test.shape[1])\n",
    "    \n",
    "    print('\\nPhase correlation')\n",
    "    \n",
    "    #Remove Collinear Variables\n",
    "    \n",
    "    tr = 0.9\n",
    "\n",
    "    corr = train.corr().abs()\n",
    "    \n",
    "    # Upper triangle of correlations\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "    \n",
    "    tr_drop = [columns for columns in upper.columns if any(upper[columns] > tr)]\n",
    "\n",
    "    print('\\nNumber of variable dropped because they were too correlated :',len(tr_drop))\n",
    "    \n",
    "    train1 = train.drop(columns = tr_drop)\n",
    "    test1 = test.drop(columns = tr_drop)\n",
    "\n",
    "    print('\\nNumber of feature in the training data after the drop of the variable too much correlated',train1.shape[1])\n",
    "    print('Number of feature in the testing data after the drop of the variable too much correlated',test1.shape[1])\n",
    "\n",
    "    print('\\nPhase Nan')\n",
    "    #Remove Missing Values\n",
    "    \n",
    "    train_missing = (train1.isnull().sum() / len(train1)).sort_values(ascending = False)\n",
    "    test_missing = (test1.isnull().sum() / len(test1)).sort_values(ascending = False)\n",
    "    \n",
    "    train_missing1 = train_missing.index[train_missing > 0.75]\n",
    "    test_missing1 = test_missing.index[test_missing > 0.75]\n",
    "\n",
    "    print('\\nNumber of columns with more than 75% of missing values in train :', len(train_missing1))\n",
    "    print('Number of columns with more than 75% of missing values in test :', len(test_missing1))\n",
    "    \n",
    "    train1 = train1.drop(columns = train_missing1 )\n",
    "    test1 = test1.drop(columns = test_missing1 )\n",
    "    \n",
    "    train, test = train1.align(test1, join = 'inner', axis = 1)\n",
    "    \n",
    "    print('\\nNumber of feature in the training data after removing missing values:', train.shape[1])\n",
    "    print('Number of feature in the testing data after removing missing values :', test.shape[1])\n",
    "    \n",
    "    \n",
    "    #MODELISATION\n",
    "    \n",
    "    coltrain = list(train.columns)\n",
    "    coltest = list(test.columns)\n",
    "\n",
    "    imputer = SimpleImputer(strategy = 'median')\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    train = imputer.fit_transform(train)\n",
    "    test = imputer.transform(test)\n",
    "    \n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "    print('\\nStart of the feature selection with LGBM attributes : feature_importances_')\n",
    "    print('')\n",
    "    \n",
    "    zero_imp = np.zeros(train.shape[1])\n",
    "    \n",
    "    while(len(zero_imp) > 0 ):\n",
    "    \n",
    "        model = LGBMClassifier()\n",
    "\n",
    "        #fit the model twice to avoid overfitting\n",
    "        feat_imp = np.zeros(train.shape[1])\n",
    "    \n",
    "        for i in range(2):\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(train, tr_labels, test_size = 0.20, random_state = i)\n",
    "    \n",
    "            model.fit(X_train, y_train, early_stopping_rounds=100, \n",
    "                 eval_set = [(X_valid, y_valid)], eval_metric = 'auc', verbose = 200)\n",
    "    \n",
    "            feat_imp += model.feature_importances_\n",
    "    \n",
    "        feat_imp = feat_imp / 2\n",
    "\n",
    "        feat_imp = pd.DataFrame({'features' : coltrain, 'importances' : feat_imp}).sort_values(by = 'importances', ascending = False)\n",
    "    \n",
    "        zero_imp = list(feat_imp[feat_imp['importances'] == 0.0]['features'])\n",
    "\n",
    "        print('\\nThe number of features with 0.0 importance is:', len(zero_imp))\n",
    "        \n",
    "        train = pd.DataFrame(train, columns = coltrain)\n",
    "        test = pd.DataFrame(test, columns = coltest)\n",
    "\n",
    "        train.drop(columns = zero_imp, inplace = True)\n",
    "        test.drop(columns = zero_imp, inplace = True)\n",
    "\n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "        \n",
    "        coltrain = list(train.columns)\n",
    "        coltest = list(test.columns)\n",
    "\n",
    "        imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "        train = imputer.fit_transform(train)\n",
    "        test = imputer.transform(test)\n",
    "        \n",
    "    print('\\n End of the features selection, we now have {} variables'.format(train.shape[1]))\n",
    "    return train, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
